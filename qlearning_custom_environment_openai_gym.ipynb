{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qlearning-custom-environment-openai-gym.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1/XevnAwzB/HHd8WLQgbl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jargnar/notebooks/blob/main/qlearning_custom_environment_openai_gym.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD6JUJZNw2sk"
      },
      "source": [
        "import numpy as np\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVex8MK_CgKe"
      },
      "source": [
        "an_example_space = Box(low=0, high=2, shape=(3,3), dtype=np.int32)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf75N9l8CtzZ",
        "outputId": "3beddb5b-96c3-45f4-9022-d78af5201fff"
      },
      "source": [
        "an_example_space.sample()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 2, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 2, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSbw_Qwg1Dbt"
      },
      "source": [
        "class SimpleFrozenLake(Env):\n",
        "  \"\"\"\n",
        "  A 3x3 grid world with 1s and 0s where one can only move right or down.\n",
        "  It's preferable to live inside 1s than in 0s in this grid world,\n",
        "  and that's what an agent must do.\n",
        "  \"\"\"\n",
        "  def __init__(self, grid):\n",
        "    self.action_space = Discrete(2)\n",
        "    self.observation_space = Box(low=0, high=1, shape=(3, 3), dtype=np.int32)\n",
        "    self.grid = np.array(grid)\n",
        "    assert self.grid.shape == (3, 3)\n",
        "    self.state = (0, 0)\n",
        "\n",
        "  def step(self, action):\n",
        "    if action == 0:\n",
        "      self.state = (self.state[0], self.state[1] + 1)\n",
        "    elif action == 1:\n",
        "      self.state = (self.state[0] + 1, self.state[1])\n",
        "    \n",
        "    done = False\n",
        "    reward = self.grid[self.state]\n",
        "    if self.state[0] == 2 or self.state[1] == 2:\n",
        "      done = True\n",
        "  \n",
        "    return self.state, reward, done, {}\n",
        "  \n",
        "  def render(self):\n",
        "    pass\n",
        "  \n",
        "  def reset(self):\n",
        "    self.state = (0, 0)\n",
        "    return self.state"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CfKuuqDKs9C"
      },
      "source": [
        "env = SimpleFrozenLake([[1, 1, 1], [0, 1, 0], [1, 0, 0]])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuDxFg4-Kwny",
        "outputId": "6a886901-9828-4a82-b48d-a3a80c04d225"
      },
      "source": [
        "qtable = np.zeros((env.observation_space.shape[0] * env.observation_space.shape[1], env.action_space.n))\n",
        "lr = 0.8\n",
        "gamma = 0.95\n",
        "eps = 1.0\n",
        "maxeps = 1.0\n",
        "mineps = 0.01 \n",
        "dr = 0.001\n",
        "\n",
        "happiness = []\n",
        "\n",
        "for episode in range(1000):\n",
        "  state = env.reset()\n",
        "  step = 0\n",
        "  done = False\n",
        "  rewards = 0\n",
        "  reward = 0\n",
        "    \n",
        "  for step in range(100):\n",
        "    ee = np.random.uniform(0, 1)\n",
        "    action = np.argmax(qtable[state,:], axis=1)[0] if ee > eps else env.action_space.sample()\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    qtable[state, action] = qtable[state, action] + lr * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
        "    rewards += reward\n",
        "    state = new_state\n",
        "    if done == True: \n",
        "        break\n",
        "        \n",
        "    episode += 1\n",
        "    eps = mineps + (maxeps - mineps)*np.exp(-dr*episode) \n",
        "    happiness.append(rewards)\n",
        "\n",
        "print(sum(happiness)/1000)\n",
        "print(qtable)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.249\n",
            "[[19.96392854 19.90523515]\n",
            " [19.96327115 19.93844323]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QVnVb07MCBn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}